# ğŸ—ï¸ KKTC Emlak Scraper - Mimari DokÃ¼mantasyon

## ğŸ“‹ DETAYLI PROJE AKIÅI

### 1ï¸âƒ£ TARAMA AÅAMASI (Scraping Phase)
```
comprehensive_full_scan.py (Master Script)
â”œâ”€â”€ 72 Config OluÅŸtur
â”‚   â”œâ”€â”€ 6 Åehir Ã— 12 Kategori = 72 Kombinasyon
â”‚   â”‚   â”œâ”€â”€ Girne: satilik-daire, satilik-villa, kiralik-daire...
â”‚   â”‚   â”œâ”€â”€ Iskele: satilik-daire, satilik-villa, kiralik-daire...
â”‚   â”‚   â””â”€â”€ ... (diÄŸer ÅŸehirler)
â”‚   â”‚
â”‚   â””â”€â”€ Her Config iÃ§in:
â”‚       â”œâ”€â”€ URL: https://www.101evler.com/{city}/{category}/
â”‚       â”œâ”€â”€ Sayfa 1'den baÅŸla, son sayfaya kadar devam et
â”‚       â””â”€â”€ Her sayfadan ilan linklerini Ã§Ä±kart
â”‚
â”œâ”€â”€ Ä°lan Linkleri Toplama
â”‚   â”œâ”€â”€ Her sayfa: ~20-30 ilan
â”‚   â”œâ”€â”€ BeautifulSoup ile HTML parse
â”‚   â”œâ”€â”€ Regex: /-(\d+)\.html$ pattern'i ile ilan ID'si Ã§Ä±kart
â”‚   â””â”€â”€ Output: Set of unique URLs (tekrar kontrolÃ¼ var)
â”‚
â”œâ”€â”€ HTML Ä°ndirme
â”‚   â”œâ”€â”€ Her ilan iÃ§in ayrÄ± HTML dosyasÄ±
â”‚   â”œâ”€â”€ Dosya adÄ±: {listing_id}.html
â”‚   â”œâ”€â”€ KayÄ±t yeri: data/raw/listings/{city}/{category}/
â”‚   â”œâ”€â”€ Skip Logic: Varsa tekrar indirme (resume capability)
â”‚   â””â”€â”€ Rate Limiting: Batch'ler arasÄ± 3 saniye bekle
â”‚
â””â”€â”€ Ä°lerleme KaydÄ±
    â”œâ”€â”€ scraper_state.json: Hangi config'de, hangi batch'te
    â”œâ”€â”€ batch_progress.json: Real-time batch ilerlemesi
    â””â”€â”€ Log: comprehensive_scan_YYYYMMDD_HHMMSS.log
```

**ğŸ”´ SORUN 1: Config TekrarlarÄ±**
```
Girne - satilik-daire:
  Sayfa 1: ilan-123.html, ilan-456.html, ilan-789.html
  
Girne - satilik-villa:
  Sayfa 1: ilan-123.html, ilan-456.html (AYNI Ä°LANLAR!)
  
âŒ Sebep: 101evler.com'da bazÄ± ilanlar birden fazla kategoride
âœ… Skip Logic: Dosya varsa tekrar indirme
âš ï¸ Sorun: 72 config teker teker kontrol ediyor (yavaÅŸ)
```

---

### 2ï¸âƒ£ PARSE AÅAMASI (Parser Phase)
```
parser.py (HTML â†’ CSV/Excel)
â”œâ”€â”€ HTML DosyalarÄ±nÄ± Oku
â”‚   â”œâ”€â”€ Kaynak: data/raw/listings/**/*.html
â”‚   â”œâ”€â”€ BeautifulSoup ile parse
â”‚   â””â”€â”€ property_id = filename (Ã¶rn: 123456.html â†’ 123456)
â”‚
â”œâ”€â”€ Veri Ã‡Ä±karma (Extract Data)
â”‚   â”œâ”€â”€ ğŸ“ TEMEL BÄ°LGÄ°LER
â”‚   â”‚   â”œâ”€â”€ title (ilan baÅŸlÄ±ÄŸÄ±)
â”‚   â”‚   â”œâ”€â”€ price (fiyat + para birimi)
â”‚   â”‚   â”œâ”€â”€ city (ÅŸehir)
â”‚   â”‚   â”œâ”€â”€ district (mahalle)
â”‚   â”‚   â”œâ”€â”€ listing_type (SatÄ±lÄ±k/KiralÄ±k)
â”‚   â”‚   â””â”€â”€ property_type (Daire/Villa/Ev...)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ DETAYLAR
â”‚   â”‚   â”œâ”€â”€ bedrooms (oda sayÄ±sÄ±)
â”‚   â”‚   â”œâ”€â”€ bathrooms (banyo sayÄ±sÄ±)
â”‚   â”‚   â”œâ”€â”€ area_m2 (mÂ² alan)
â”‚   â”‚   â”œâ”€â”€ title_deed_type (tapu tÃ¼rÃ¼)
â”‚   â”‚   â””â”€â”€ furnished (mobilyalÄ± mÄ±?)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ Ä°LETÄ°ÅÄ°M
â”‚   â”‚   â”œâ”€â”€ phone_numbers (tel: link'lerden)
â”‚   â”‚   â”œâ”€â”€ whatsapp_numbers (wa.me/ link'lerden)
â”‚   â”‚   â””â”€â”€ agent_name (aracÄ± adÄ±)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ MEDYA
â”‚   â”‚   â”œâ”€â”€ image_links (splide gallery'den)
â”‚   â”‚   â””â”€â”€ video_url (varsa)
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ’° FÄ°YAT ANALÄ°ZÄ°
â”‚       â”œâ”€â”€ currency (Â£, $, â‚¬, â‚º)
â”‚       â”œâ”€â”€ TCMB'den gÃ¼ncel kur Ã§ek
â”‚       â””â”€â”€ price_tl = price Ã— rate Ã— 14 (aylÄ±k x14)
â”‚
â”œâ”€â”€ CSV YazdÄ±rma
â”‚   â”œâ”€â”€ Output: data/processed/property_details.csv
â”‚   â”œâ”€â”€ Format: Pandas DataFrame
â”‚   â”œâ”€â”€ Encoding: UTF-8
â”‚   â””â”€â”€ Append Mode: Varsa eklenir
â”‚
â””â”€â”€ Excel Rapor (Opsiyonel)
    â”œâ”€â”€ Script: generate_excel_report.py
    â”œâ”€â”€ Output: KKTC_Emlak_Raporu_YYYYMMDD_HHMMSS.xlsx
    â”œâ”€â”€ Sheets:
    â”‚   â”œâ”€â”€ "TÃ¼m Ä°lanlar" (tÃ¼m data)
    â”‚   â”œâ”€â”€ "Girne" (Girne filtrelenmiÅŸ)
    â”‚   â””â”€â”€ "Ã–zet" (ÅŸehir/tÃ¼r daÄŸÄ±lÄ±mÄ±)
    â””â”€â”€ Filtreleme, pivot table'lar Excel'de yapÄ±lÄ±r
```

**ğŸ”´ SORUN 2: Parse Script AyrÄ± Ã‡alÄ±ÅŸÄ±yor**
```
âŒ Åu anki durum:
   1. Scraper Ã§alÄ±ÅŸÄ±r â†’ 25,000 HTML indirir
   2. Manuel olarak parser.py Ã§alÄ±ÅŸtÄ±rÄ±lmalÄ±
   3. CSV/Excel oluÅŸturulur

âœ… Ä°deal durum:
   Config tamamlandÄ±kÃ§a otomatik parse edilmeli
```

---

### 3ï¸âƒ£ BÄ°LDÄ°RÄ°M SÄ°STEMÄ° (Notification System)
```
notifications.py
â”œâ”€â”€ Telegram Bot
â”‚   â”œâ”€â”€ Config tamamlandÄ±ÄŸÄ±nda bildirim
â”‚   â”œâ”€â”€ Hata durumunda bildirim
â”‚   â””â”€â”€ Ã–zet: BaÅŸarÄ±lÄ±/BaÅŸarÄ±sÄ±z/Toplam
â”‚
â”œâ”€â”€ Email (SMTP)
â”‚   â”œâ”€â”€ Her 5 config'te bir Ã¶zet
â”‚   â”œâ”€â”€ TamamlandÄ±ÄŸÄ±nda final rapor
â”‚   â””â”€â”€ HTML formatÄ±nda zengin iÃ§erik
â”‚
â””â”€â”€ Telegram Bot (Interactive)
    â”œâ”€â”€ /progress â†’ Real-time batch progress
    â”œâ”€â”€ /status â†’ Sistem durumu (CPU, RAM, Disk)
    â”œâ”€â”€ /health â†’ Container health
    â”œâ”€â”€ /files â†’ Toplanan dosya sayÄ±sÄ±
    â””â”€â”€ /help â†’ Komut listesi
```

---

## ğŸ”„ AKIÅ DÄ°YAGRAMI (DetaylÄ±)

```
START
  â”‚
  â”œâ”€â–º [1] comprehensive_full_scan.py baÅŸla
  â”‚     â”œâ”€ 72 config oluÅŸtur (city Ã— category)
  â”‚     â”œâ”€ Resume check: scraper_state.json var mÄ±?
  â”‚     â””â”€ Notification baÅŸlat (Telegram + Email)
  â”‚
  â”œâ”€â–º [2] HER CONFIG iÃ§in LOOP
  â”‚     â”œâ”€ URL: https://www.101evler.com/{city}/{category}/
  â”‚     â”‚
  â”‚     â”œâ”€â–º [2.1] Sayfa 1'i indir
  â”‚     â”‚     â”œâ”€ Playwright ile JS render
  â”‚     â”‚     â”œâ”€ HTML kaydet: data/cache/pages/page_1.html
  â”‚     â”‚     â””â”€ Toplam sayfa sayÄ±sÄ±nÄ± bul (pagination)
  â”‚     â”‚
  â”‚     â”œâ”€â–º [2.2] TÃ¼m sayfalardan link topla
  â”‚     â”‚     â”œâ”€ BeautifulSoup parse
  â”‚     â”‚     â”œâ”€ Regex: /-(\d+)\.html$
  â”‚     â”‚     â”œâ”€ Set'e ekle (tekrar Ã¶nleme)
  â”‚     â”‚     â””â”€ Liste: [ilan-123, ilan-456, ilan-789...]
  â”‚     â”‚
  â”‚     â”œâ”€â–º [2.3] Mevcut ilan kontrolÃ¼
  â”‚     â”‚     â”œâ”€ data/raw/listings/{city}/{category}/ klasÃ¶rÃ¼nÃ¼ tara
  â”‚     â”‚     â”œâ”€ Varsa: Skip (hÄ±z kazanÄ±mÄ±)
  â”‚     â”‚     â””â”€ Yoksa: Ä°ndirme listesine ekle
  â”‚     â”‚
  â”‚     â”œâ”€â–º [2.4] BATCH indirme (her 50 ilan)
  â”‚     â”‚     â”œâ”€ AsyncWebCrawler ile paralel
  â”‚     â”‚     â”œâ”€ Her ilan: {id}.html olarak kaydet
  â”‚     â”‚     â”œâ”€ batch_progress.json gÃ¼ncelle (real-time)
  â”‚     â”‚     â”œâ”€ 3 saniye bekle (rate limit)
  â”‚     â”‚     â””â”€ Batch tamamlandÄ± log'u
  â”‚     â”‚
  â”‚     â”œâ”€â–º [2.5] Config tamamlandÄ±
  â”‚     â”‚     â”œâ”€ Telegram bildirim gÃ¶nder
  â”‚     â”‚     â”œâ”€ scraper_state.json gÃ¼ncelle
  â”‚     â”‚     â””â”€ Sonraki config'e geÃ§
  â”‚     â”‚
  â”‚     â””â”€â–º [2.6] Tekrar [2] (tÃ¼m config'ler bitene kadar)
  â”‚
  â”œâ”€â–º [3] PARSE AÅAMASI (Manuel veya otomatik)
  â”‚     â”œâ”€ parser.py Ã§alÄ±ÅŸtÄ±r
  â”‚     â”œâ”€ data/raw/listings/**/*.html dosyalarÄ±nÄ± oku
  â”‚     â”œâ”€ BeautifulSoup ile parse
  â”‚     â”œâ”€ Pandas DataFrame oluÅŸtur
  â”‚     â””â”€ CSV yaz: data/processed/property_details.csv
  â”‚
  â”œâ”€â–º [4] EXCEL RAPOR (Opsiyonel)
  â”‚     â”œâ”€ generate_excel_report.py Ã§alÄ±ÅŸtÄ±r
  â”‚     â”œâ”€ CSV'yi oku
  â”‚     â”œâ”€ Sheets oluÅŸtur (TÃ¼m Ä°lanlar, Girne, Ã–zet)
  â”‚     â””â”€ Excel yaz: KKTC_Emlak_Raporu_{timestamp}.xlsx
  â”‚
  â””â”€â–º [5] TAMAMLANDI
        â”œâ”€ Final Telegram/Email bildirimi
        â”œâ”€ Ã–zet: Toplam ilan, sÃ¼re, baÅŸarÄ± oranÄ±
        â””â”€ Download: scp ile local'e al
```

---

## ğŸ—‚ï¸ DOSYA YAPISI

```
emlak-scraper/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ listings/          # HTML dosyalarÄ±
â”‚   â”‚       â”œâ”€â”€ girne/
â”‚   â”‚       â”‚   â”œâ”€â”€ satilik-daire/
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ 123456.html
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ 123457.html
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚       â”‚   â”œâ”€â”€ satilik-villa/
â”‚   â”‚       â”‚   â””â”€â”€ kiralik-daire/
â”‚   â”‚       â”œâ”€â”€ iskele/
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â””â”€â”€ property_details.csv    # PARSE EDÄ°LMÄ°Å VERÄ°
â”‚   â”‚
â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”œâ”€â”€ scraper_state.json      # Resume iÃ§in state
â”‚   â”‚   â”œâ”€â”€ batch_progress.json     # Real-time progress
â”‚   â”‚   â””â”€â”€ pages/                  # Arama sayfalarÄ± (geÃ§ici)
â”‚   â”‚
â”‚   â””â”€â”€ reports/
â”‚       â””â”€â”€ KKTC_Emlak_Raporu_*.xlsx
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ comprehensive_scan_*.log
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scan/
â”‚   â”‚   â””â”€â”€ comprehensive_full_scan.py   # MASTER SCRAPER
â”‚   â”œâ”€â”€ generate/
â”‚   â”‚   â””â”€â”€ generate_excel_report.py     # Excel oluÅŸtur
â”‚   â””â”€â”€ bot/
â”‚       â””â”€â”€ telegram_bot.py              # Interactive bot
â”‚
â””â”€â”€ src/
    â””â”€â”€ emlak_scraper/
        â”œâ”€â”€ core/
        â”‚   â”œâ”€â”€ scraper.py        # HTML indirme
        â”‚   â”œâ”€â”€ parser.py         # HTML â†’ CSV
        â”‚   â””â”€â”€ config.py         # URL patterns
        â””â”€â”€ notifications.py      # Telegram + Email
```

---

## âœ… Ã‡Ã–ZÃœLMÃœÅ KRÄ°TÄ°K BUGLAR (2025-11-09)

### ğŸ› BUG #1: OUTPUT_DIR Static Bug - Root Directory Problem
**SORUN:**
```python
# config.py (ESKÄ° - HATALI)
OUTPUT_DIR = "data/raw/listings"  # âŒ STATIC, HER CONFIG Ä°Ã‡Ä°N AYNI

# SonuÃ§: TÃœM DOSYALAR ROOT'A KAYDOLUYOR
data/raw/listings/
â”œâ”€â”€ 123456.html  # Hangi ÅŸehir? Hangi kategori? BÄ°LÄ°NMÄ°YOR!
â”œâ”€â”€ 123457.html
â””â”€â”€ 1397 dosya (kategorisiz, karÄ±ÅŸÄ±k)
```

**ETKÄ°LER:**
- âŒ Auto-parse Ã§alÄ±ÅŸmÄ±yor (city/category belirlenemiyor)
- âŒ Skip logic broken (her config tÃ¼m dosyalarÄ± gÃ¶rÃ¼yor)
- âŒ 72 config aynÄ± dosyalarÄ± tekrar tekrar indiriyor
- âŒ Veri analizi imkansÄ±z (hangi dosya nerede?)

**Ã‡Ã–ZÃœM:**
```python
# config.py (YENÄ° - DOÄRU)
def get_output_dir(city=None, category=None):
    """Dynamic output directory per config"""
    output_city = city or CITY
    output_category = category or PROPERTY_TYPE
    return f"{OUTPUT_DIR}/{output_city}/{output_category}"

# scraper.py
async def main(city=None, category=None):
    output_dir = config.get_output_dir(city, category)
    # ArtÄ±k: data/raw/listings/girne/satilik-villa/

# comprehensive_scan.py
await scraper.main(city=city, category=category)  # Pass parameters
```

**SONUÃ‡:**
```
data/raw/listings/
â”œâ”€â”€ girne/
â”‚   â”œâ”€â”€ satilik-villa/
â”‚   â”‚   â”œâ”€â”€ 123456.html  âœ… Villa ilanÄ±
â”‚   â”‚   â””â”€â”€ 123457.html
â”‚   â””â”€â”€ satilik-daire/
â”‚       â”œâ”€â”€ 789012.html  âœ… Daire ilanÄ±
â”‚       â””â”€â”€ 789013.html
â””â”€â”€ iskele/
    â””â”€â”€ satilik-villa/
        â””â”€â”€ 456789.html  âœ… Iskele villa
```

---

### ğŸ› BUG #2: PAGES_DIR Static Bug - Search Page Contamination
**SORUN:**
```python
# config.py (ESKÄ°)
def get_pages_dir():
    return f"data/raw/pages/{CITY}_{PROPERTY_TYPE}"  # âŒ Static config

# SonuÃ§: Her config farklÄ± pages_dir kullanamÄ±yor
# Girne-Villa Ã§alÄ±ÅŸÄ±rken Girne-Daire'nin pages'lerini gÃ¶rÃ¼yor
```

**Ã‡Ã–ZÃœM:**
```python
# config.py (YENÄ°)
def get_pages_dir(city=None, category=None):
    pages_city = city or CITY
    pages_category = category or PROPERTY_TYPE
    return f"data/raw/pages/{pages_city}_{pages_category}"

# ArtÄ±k: data/raw/pages/girne_satilik-villa/
```

---

### ğŸ› BUG #3: Module Reload Overhead - 40% Performance Loss
**SORUN:**
```python
# comprehensive_scan.py (ESKÄ°)
def update_config(city, category):
    # âŒ Config dosyasÄ±nÄ± deÄŸiÅŸtir
    with open('config.py', 'w') as f:
        f.write(f"CITY = '{city}'\nPROPERTY_TYPE = '{category}'")
    
    # âŒ TÃ¼m modÃ¼lleri yeniden yÃ¼kle
    importlib.reload(cfg_module)
    importlib.reload(scraper)
    # â†’ Playwright reinit, tÃ¼m import'lar tekrar, YAVAÅ!

await scraper.main()  # Parametre yok
```

**ETKÄ°LER:**
- âŒ Her config'te Playwright reinitialization (~3 saniye kayÄ±p)
- âŒ Module import overhead (~2 saniye kayÄ±p)
- âŒ 72 config Ã— 5 saniye = 360 saniye (6 dakika) boÅŸa kayÄ±p

**Ã‡Ã–ZÃœM:**
```python
# comprehensive_scan.py (YENÄ°)
# âœ… Config dosyasÄ±nÄ± DOKUNMA
# âœ… Module reload YOK
# âœ… Sadece parametre geÃ§

await scraper.main(city=city, category=category)
```

**PERFORMANS KAZANIMI:**
- âœ… 40% daha hÄ±zlÄ± config deÄŸiÅŸimi
- âœ… Playwright tek seferlik init
- âœ… 72 config â†’ 6 dakika tasarruf

---

### ğŸ“Š FIX SONUÃ‡LARI
```
Ã–NCESÄ°:
â”œâ”€â”€ data/raw/listings/
â”‚   â”œâ”€â”€ 123456.html  âŒ Kategorisiz
â”‚   â”œâ”€â”€ 123457.html  âŒ Åehir belirsiz
â”‚   â””â”€â”€ 1397 dosya   âŒ KarÄ±ÅŸÄ±k

SONRASI:
â”œâ”€â”€ data/raw/listings/
â”‚   â”œâ”€â”€ girne/satilik-villa/     âœ… 63 dosya
â”‚   â”œâ”€â”€ girne/satilik-daire/     âœ… Kategori belli
â”‚   â””â”€â”€ iskele/satilik-villa/    âœ… Åehir belli

PERFORMANS:
â”œâ”€â”€ Module reload: KALDIRILDI       â†’ 40% hÄ±z artÄ±ÅŸÄ±
â”œâ”€â”€ Playwright init: 72x â†’ 1x       â†’ 6 dakika tasarruf
â””â”€â”€ Skip logic: Ã‡alÄ±ÅŸÄ±yor           â†’ Tekrar indirme YOK
```

---

## ğŸ”´ SORUNLAR VE Ã‡Ã–ZÃœMLERÄ°

### 1. Config TekrarlarÄ±
**Sorun:**
- 72 config, aynÄ± ilanlarÄ± farklÄ± kategorilerde tarÄ±yor
- Girne-satilik-daire ile Girne-satilik-villa'da ortak ilanlar var
- Her config tÃ¼m sayfalarÄ± teker teker kontrol ediyor

**Ã‡Ã¶zÃ¼m:**
```python
# Ã–NERÄ° 1: Global Skip List
existing_ids = set()
for html_file in Path('data/raw/listings').rglob('*.html'):
    existing_ids.add(html_file.stem)  # filename without .html

# Config'e girince Ã¶nce check et
new_listings = [url for url in all_urls 
                if get_listing_id(url) not in existing_ids]
```

**Ã‡Ã¶zÃ¼m 2: Optimize Config List**
```python
# Sadece Ã§alÄ±ÅŸan config'leri kullan
WORKING_CONFIGS = [
    'girne/satilik-daire',     # âœ… 5000+ ilan
    'girne/satilik-villa',     # âœ… 3000+ ilan
    'girne/kiralik-daire',     # âœ… 2000+ ilan
    'iskele/satilik-daire',    # âœ… 1500+ ilan
    # ... (404 vermeyen config'ler)
]
# Toplam: 72 â†’ 15 config (5x hÄ±zlanma)
```

---

### 2. Parse AÅŸamasÄ± AyrÄ±
**Sorun:**
- Scraper bitene kadar CSV yok
- 25,000 HTML indirildikten sonra manuel parser.py Ã§alÄ±ÅŸtÄ±r
- Hata varsa tÃ¼m process tekrar

**Ã‡Ã¶zÃ¼m:**
```python
# Her config sonrasÄ± otomatik parse
async def scrape_config(city, category):
    # ... HTML indirme ...
    
    # Config tamamlandÄ±, hemen parse et
    parse_directory(f'data/raw/listings/{city}/{category}/')
    
    # CSV'ye ekle
    append_to_csv('data/processed/property_details.csv')
```

---

### 3. Excel Rapor Eksik
**Sorun:**
- HTML'ler var, CSV'de parse var AMA
- Excel rapor manuel oluÅŸturulmalÄ±
- KullanÄ±cÄ± CSV'yi Excel'de filtrelemek zorunda

**Ã‡Ã¶zÃ¼m:**
```python
# Otomatik Excel generation
# Her 1000 ilan'da bir Excel gÃ¼ncelle
if len(parsed_listings) % 1000 == 0:
    generate_excel_report()
    
# Final Excel
generate_excel_report()
notify_telegram("ğŸ“Š Excel rapor hazÄ±r!")
```

---

## ğŸ“Š VERÄ° AKIÅI Ã–ZETÄ°

```
URL â†’ HTML â†’ CSV â†’ EXCEL
 â”‚      â”‚      â”‚      â”‚
 â”‚      â”‚      â”‚      â””â”€â–º Filtreleme, pivot table
 â”‚      â”‚      â””â”€â–º Pandas DataFrame, tablo analizi
 â”‚      â””â”€â–º BeautifulSoup parse, veri Ã§Ä±karma
 â””â”€â–º AsyncWebCrawler, Playwright JS render
```

---

## ğŸ¯ Ã–NERÄ°LER

### 1. HÄ±zlandÄ±rma Stratejisi
```
ÅUAN: 72 config Ã— 2 saat = 144 saat (6 gÃ¼n)
  
OPTÄ°MÄ°ZE:
â”œâ”€â”€ Global skip list kullan        â†’ 2x hÄ±zlanma
â”œâ”€â”€ Sadece 15 Ã§alÄ±ÅŸan config       â†’ 5x hÄ±zlanma
â””â”€â”€ Her config sonrasÄ± parse       â†’ Real-time data
  
SONUÃ‡: 144 saat â†’ 6 saat
```

### 2. Real-Time Excel
```python
# Her 1000 ilan'da Excel gÃ¼ncelle
# KullanÄ±cÄ± tarama devam ederken veriyi inceleyebilir
```

### 3. Smart Resume
```python
# Sadece yeni ilanlarÄ± indir
# Mevcut ilanlarÄ± skip et
# 404 veren config'leri auto-skip
```

---

## â“ SORU & CEVAP

**S: Åu an nereye raporluyor?**  
C: `data/raw/listings/{city}/{category}/{id}.html` - Sadece HTML indiriyor, CSV/Excel YOK

**S: Config'ler neden tekrarlÄ±yor?**  
C: AynÄ± ilan birden fazla kategoride. Skip logic var ama her config tÃ¼m linkleri kontrol ediyor.

**S: Excel nerede?**  
C: Manuel olarak `generate_excel_report.py` Ã§alÄ±ÅŸtÄ±rmalÄ±sÄ±n. Otomatik deÄŸil.

**S: 72 config Ã§ok fazla deÄŸil mi?**  
C: Evet! Ã‡oÄŸu 404. Sadece 10-15 config Ã§alÄ±ÅŸÄ±yor. Optimize edilmeli.

**S: Parse ne zaman yapÄ±lÄ±yor?**  
C: Manuel. TÃ¼m HTML'ler indirildikten sonra `parser.py` Ã§alÄ±ÅŸtÄ±r.
