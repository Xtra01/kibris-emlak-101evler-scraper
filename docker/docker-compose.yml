services:
  scraper:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: kibris-emlak-scraper
    volumes:
      # Persist data directories (new structure)
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      # Python environment
      - PYTHONUNBUFFERED=1
      # Add any custom environment variables here
      # - CUSTOM_VAR=value
    restart: unless-stopped
    networks:
      - scraper-network
    # Resource limits (adjust based on your needs)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    # Override default command for different operations
    # Uncomment one of the following or override via docker-compose run
  # command: python -m emlak_scraper.core.scraper  # Default scraper
  # command: python -m emlak_scraper.core.parser  # Run extractor
  # command: python -m emlak_scraper.reports.markdown  # Generate reports
  # command: python -m emlak_scraper.analysis.orchard  # Run orchard analysis
  # command: python -m emlak_scraper.reports.agents  # Generate Word report
    # command: /bin/bash  # Interactive shell

  # Optional: Add a scheduled job service using cron
  scraper-scheduler:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: kibris-emlak-scheduler
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./crontab:/etc/cron.d/scraper-cron:ro
    environment:
      - PYTHONUNBUFFERED=1
    command: >
      sh -c "
      apt-get update && 
      apt-get install -y cron && 
      crontab /etc/cron.d/scraper-cron && 
      cron -f
      "
    restart: unless-stopped
    networks:
      - scraper-network
    profiles:
      - scheduler
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

networks:
  scraper-network:
    driver: bridge
