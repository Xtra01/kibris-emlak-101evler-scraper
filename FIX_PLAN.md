# ğŸš¨ CRITICAL BUG FIX PLAN

## ğŸ”´ DETECTED ISSUES:

### BUG #1: DOSYA YAPISI HATASI (CRITICAL)
**Problem:**
- TÃ¼m HTML dosyalarÄ± `/app/data/raw/listings/` ROOT'a kaydediliyor
- City/category klasÃ¶r yapÄ±sÄ± YOK
- 1397 dosya tek klasÃ¶rde
- Parse script city/category'yi bulamÄ±yor

**Evidence:**
```bash
/app/data/raw/listings/
â”œâ”€â”€ 158288.html  â† Hangi ÅŸehir? Hangi kategori? BÄ°LÄ°NMÄ°YOR!
â”œâ”€â”€ 213198.html
â””â”€â”€ ...
```

**Expected:**
```bash
/app/data/raw/listings/
â”œâ”€â”€ girne/
â”‚   â”œâ”€â”€ satilik-daire/
â”‚   â”‚   â”œâ”€â”€ 158288.html
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ satilik-villa/
â”‚       â”œâ”€â”€ 213198.html
â”‚       â””â”€â”€ ...
```

---

### BUG #2: CONFIG.PY OUTPUT_DIR SABÄ°T
**Problem:**
```python
# src/emlak_scraper/core/config.py
OUTPUT_DIR = "data/raw/listings"  # âŒ ALWAYS THE SAME!
```

**Impact:**
- `comprehensive_scan.py` config'i deÄŸiÅŸtiriyor ama OUTPUT_DIR DEÄÄ°ÅMÄ°YOR
- Her config aynÄ± klasÃ¶re yazÄ±yor
- Dosya adÄ± collision, metadata loss

---

### BUG #3: SCRAPER OUTPUT_DIR KULLANIMI
**Problem:**
```python
# src/emlak_scraper/core/scraper.py:121
async def save_html_to_file(html_content, url, output_dir):
    filepath = os.path.join(output_dir, filename)  # âŒ No city/category!
```

**Impact:**
- `save_html_to_file()` sadece base output_dir kullanÄ±yor
- City/category subdirectory oluÅŸturmuyor

---

### BUG #4: MODULE RELOAD OVERHEAD
**Problem:**
```python
# comprehensive_scan.py her config iÃ§in:
importlib.reload(cfg_module)  # Config file deÄŸiÅŸtir
importlib.reload(scraper)     # Module reload (SLOW!)
```

**Impact:**
- Her config iÃ§in 2x module reload
- Playwright reinit
- Gereksiz overhead

---

### BUG #5: SKIP LOGIC Ã‡ALIÅMIYOR
**Problem:**
```python
# scraper.py:78
def get_existing_listing_ids(output_dir):
    for filename in os.listdir(output_dir):  # âŒ Sadece o config'in klasÃ¶rÃ¼!
```

**Impact:**
- Config 1: `girne/satilik-daire/` â†’ 123.html indirir
- Config 2: `girne/satilik-villa/` â†’ 123.html'i gÃ¶remez, TEKRAR indirir!
- Ã‡Ã¼nkÃ¼ farklÄ± output_dir!

---

## âœ… FIX SOLUTIONS:

### FIX #1: OUTPUT_DIR DÄ°NAMÄ°K YAPILMALI
```python
# config.py
def get_output_dir(city: str, category: str) -> str:
    return f"data/raw/listings/{city}/{category}"

# comprehensive_scan.py
output_dir = config.get_output_dir(city, category)
```

### FIX #2: SCRAPER'A CITY/CATEGORY PARAMETRE
```python
# scraper.py main() fonksiyonuna parametre ekle
async def main(city: str = None, category: str = None):
    if city and category:
        output_dir = f"{config.OUTPUT_DIR}/{city}/{category}"
    else:
        # Legacy mode: config.py'den al
        output_dir = config.OUTPUT_DIR
```

### FIX #3: GLOBAL SKIP LIST
```python
# Her config baÅŸlamadan Ã–NCE:
all_existing_ids = set()
for html_file in Path('data/raw/listings').rglob('*.html'):
    all_existing_ids.add(html_file.stem)

# Config Ã§alÄ±ÅŸÄ±rken:
new_listings = [url for url in urls if get_id(url) not in all_existing_ids]
```

### FIX #4: MODULE RELOAD KALDIR
```python
# âŒ OLD: Config dosyasÄ±nÄ± deÄŸiÅŸtir + reload
# âœ… NEW: Config'i parametre olarak geÃ§ir

await scraper.main(city=city, category=category)  # No reload needed!
```

---

## ğŸ¯ IMPLEMENTATION PLAN:

### Phase 1: CRITICAL FIXES (STOP DATA LOSS)
1. âœ… `config.py`: Add `get_output_dir(city, category)` function
2. âœ… `scraper.py`: Update `main()` to accept city/category params
3. âœ… `scraper.py`: Update `save_html_to_file()` to use dynamic path
4. âœ… `comprehensive_scan.py`: Pass city/category to scraper.main()
5. âœ… Remove module reload logic

### Phase 2: GLOBAL SKIP LIST (SPEED UP)
1. âœ… Create `get_all_existing_ids()` function
2. âœ… Build global set ONCE before loop
3. âœ… Pass existing_ids to each config

### Phase 3: RE-ORGANIZE EXISTING DATA
1. âœ… Stop current scan
2. âœ… Analyze log: Which config was running when each file was saved?
3. âœ… Move files from root to proper `{city}/{category}/` folders
4. âœ… Resume scan

---

## ğŸ“Š EXPECTED RESULTS:

**Before:**
```
109 batch / 302 total (36%)
Runtime: ~18 minutes
Files: 1397 (all in root)
Structure: BROKEN âŒ
```

**After:**
```
Structure:
data/raw/listings/
â”œâ”€â”€ girne/
â”‚   â”œâ”€â”€ satilik-daire/
â”‚   â”‚   â”œâ”€â”€ 123456.html
â”‚   â”‚   â””â”€â”€ ... (500+ files)
â”‚   â””â”€â”€ satilik-villa/
â”‚       â”œâ”€â”€ 234567.html
â”‚       â””â”€â”€ ... (897 files)
â””â”€â”€ ...

âœ… Parse'a hazÄ±r
âœ… Auto-parse Ã§alÄ±ÅŸabilir
âœ… Excel generation mÃ¼mkÃ¼n
```

---

## ğŸš€ NEXT STEPS:

1. **STOP SCAN** (data loss Ã¶nleme)
2. **FIX CODE** (yukarÄ±daki changes)
3. **REORGANIZE FILES** (1397 dosyayÄ± dÃ¼zelt)
4. **RESTART SCAN** (doÄŸru yapÄ±yla)
5. **VERIFY** (1-2 config test et)
6. **FULL RUN** (optimize edilmiÅŸ 15 config)

---

## ğŸ’¡ BONUS: SMART SCAN IDEA

Config bazlÄ± deÄŸil, **ilan bazlÄ±** tarama:

```python
# TÃ¼m sayfalardaki tÃ¼m linkleri topla (HIZLI!)
all_urls = set()
for city in CITIES:
    for category in CATEGORIES:
        urls = await get_all_links(city, category)
        all_urls.update(urls)

# Unique ID'leri Ã§Ä±kart
unique_ids = {get_id(url) for url in all_urls}
# Ã–rnek: 25,000 unique ilan

# Sadece yeni olanlarÄ± indir
new_ids = unique_ids - existing_ids
# Batch download
# 1 PASS = 25K Ä°LAN!
```

**Avantaj:**
- Config tekrarÄ± YOK
- 72 loop â†’ 1 loop
- 144 saat â†’ 6 saat
