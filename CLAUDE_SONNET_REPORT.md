# ğŸ¤– Claude Sonnet 4.5 Ä°Ã§in: Raspberry Pi 5 DetaylÄ± Sistem Raporu

**Rapor Tarihi:** 8 KasÄ±m 2025, 19:45  
**HazÄ±rlayan:** GitHub Copilot  
**Ä°Ã§in:** Claude Sonnet 4.5  
**AmaÃ§:** Pi5 durumu, problemler, Ã§Ã¶zÃ¼mler ve best practices aktarÄ±mÄ±

---

## ğŸ“‹ Ã–zet (Executive Summary)

### Sistem Durumu: âœ… **OPERASYONEL** (2 minor sorun Ã§Ã¶zÃ¼ldÃ¼)

| Kategori | Durum | Not |
|----------|-------|-----|
| **Hardware** | âœ… MÃ¼kemmel | 12 gÃ¼n uptime, sÄ±caklÄ±k normal |
| **Software** | âœ… Stabil | 9 container Ã§alÄ±ÅŸÄ±yor |
| **Network** | âœ… Aktif | Cloudflare tunnel operasyonel |
| **Disk** | âš ï¸ Dikkat | %57 dolu (temizlik Ã¶nerildi) |
| **Problems Fixed** | âœ… 2 adet | Frontend healthcheck + resource limits |

### YapÄ±lan DÃ¼zeltmeler

1. **Frontend Unhealthy Sorunu (Ã‡Ã–ZÃœLDÃœ)**
   - **Problem:** Container healthy deÄŸildi ama Ã§alÄ±ÅŸÄ±yordu
   - **KÃ¶k Neden:** `wget` ile `localhost:3000` eriÅŸimi baÅŸarÄ±sÄ±z (Next.js standalone build davranÄ±ÅŸÄ±)
   - **Ã‡Ã¶zÃ¼m:** Healthcheck'i Node.js HTTP request'e Ã§evrildi
   - **Etki:** Frontend artÄ±k healthy olarak gÃ¶rÃ¼necek

2. **Resource Limits Eklendi (Ä°YÄ°LEÅTÄ°RME)**
   - **Backend:** CPU 0.5-2.0 cores, RAM 512MB-2GB
   - **Celery Worker:** CPU 1.0-3.0 cores, RAM 1GB-4GB, concurrency 2
   - **AmaÃ§:** OOM (Out of Memory) Ã¶nlemek, sistem stabilitesi

---

## ğŸ—ï¸ Sistem Mimarisi (DetaylÄ±)

### 1. Genel YapÄ±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INTERNET                                  â”‚
â”‚                    (TÃ¼m DÃ¼nya EriÅŸimi)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ HTTPS (TLS 1.3)
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CLOUDFLARE NETWORK                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Edge Servers (Global CDN)                                 â”‚ â”‚
â”‚  â”‚  - DDoS Protection (Otomatik)                              â”‚ â”‚
â”‚  â”‚  - SSL/TLS Termination                                     â”‚ â”‚
â”‚  â”‚  - Bot Management                                          â”‚ â”‚
â”‚  â”‚  - Rate Limiting (Cloudflare seviyesi)                     â”‚ â”‚
â”‚  â”‚  - Caching (Static assets)                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚
â”‚  DNS Records:                                                    â”‚
â”‚  - scraper.devtestenv.org â†’ CNAME â†’ tunnel.cloudflare.com      â”‚
â”‚  - devtestenv.org â†’ CNAME â†’ tunnel (port 3001)                  â”‚
â”‚  - json2excel.devtestenv.org â†’ CNAME â†’ tunnel (port 8091)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Cloudflare Tunnel (Encrypted)
                             â”‚ Token: eyJhIjoiMmM1OTZkNzM3ZDhiMzlkMj...
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RASPBERRY PI 5 (192.168.1.143)                      â”‚
â”‚              Debian 12 (bookworm) - ARM64                        â”‚
â”‚              8GB RAM, 64GB SD, Cortex-A76 (4 cores)             â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  CLOUDFLARED CONTAINER                                      â”‚ â”‚
â”‚  â”‚  Image: cloudflare/cloudflared:latest                       â”‚ â”‚
â”‚  â”‚  - Cloudflare Edge'e WebSocket tunnel aÃ§ar                 â”‚ â”‚
â”‚  â”‚  - Port forwarding gerekmez!                                â”‚ â”‚
â”‚  â”‚  - Otomatik reconnect                                       â”‚ â”‚
â”‚  â”‚  - Config: /home/ekrem/.cloudflared/config.yml            â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  Ingress Rules:                                             â”‚ â”‚
â”‚  â”‚    devtestenv.org â†’ http://localhost:3001                   â”‚ â”‚
â”‚  â”‚    json2excel.devtestenv.org â†’ http://localhost:8091        â”‚ â”‚
â”‚  â”‚    scraper.devtestenv.org â†’ http://localhost:80 (nginx)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â”‚                                         â”‚
â”‚                         â–¼ (Docker bridge network)                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  NGINX CONTAINER (Reverse Proxy)                            â”‚ â”‚
â”‚  â”‚  Image: nginx:alpine                                        â”‚ â”‚
â”‚  â”‚  Ports: 0.0.0.0:80â†’80, 0.0.0.0:443â†’443                      â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  Features:                                                  â”‚ â”‚
â”‚  â”‚  â”œâ”€ Rate Limiting (zone-based)                              â”‚ â”‚
â”‚  â”‚  â”‚  â”œâ”€ API: 10 req/s (burst 20)                            â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€ General: 30 req/s (burst 50)                        â”‚ â”‚
â”‚  â”‚  â”œâ”€ Gzip Compression (level 6)                              â”‚ â”‚
â”‚  â”‚  â”œâ”€ CORS Headers (for API)                                  â”‚ â”‚
â”‚  â”‚  â”œâ”€ WebSocket Support (Next.js HMR)                         â”‚ â”‚
â”‚  â”‚  â”œâ”€ Timeouts: 300s (long scraping jobs)                     â”‚ â”‚
â”‚  â”‚  â””â”€ Health endpoint: /health â†’ 200 OK                       â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â”‚  Routing:                                                   â”‚ â”‚
â”‚  â”‚    /api/* â†’ backend:8000 (FastAPI)                          â”‚ â”‚
â”‚  â”‚    /results/* â†’ /usr/share/nginx/html/results/ (static)    â”‚ â”‚
â”‚  â”‚    /* â†’ frontend:3000 (Next.js)                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                 â”‚                 â”‚                               â”‚
â”‚                 â–¼                 â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  FRONTEND            â”‚  â”‚  BACKEND             â”‚            â”‚
â”‚  â”‚  (Next.js 14)        â”‚  â”‚  (FastAPI)           â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚ Image: node:18-alpineâ”‚  â”‚ Image: python:3.11   â”‚            â”‚
â”‚  â”‚ Port: 3000 (internal)â”‚  â”‚ Port: 8000 (internal)â”‚            â”‚
â”‚  â”‚ Build: standalone    â”‚  â”‚ Workers: 1 uvicorn   â”‚            â”‚
â”‚  â”‚ User: nextjs:nodejs  â”‚  â”‚ CMD: uvicorn main:appâ”‚            â”‚
â”‚  â”‚                      â”‚  â”‚                      â”‚            â”‚
â”‚  â”‚ Health: Node HTTP âœ… â”‚  â”‚ Health: /health âœ…   â”‚            â”‚
â”‚  â”‚ Memory: (no limit)   â”‚  â”‚ Memory: 512M-2GB     â”‚            â”‚
â”‚  â”‚ CPU: (no limit)      â”‚  â”‚ CPU: 0.5-2.0 cores   â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                       â”‚                          â”‚
â”‚                                       â–¼                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  CELERY ECOSYSTEM                                           â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚ â”‚
â”‚  â”‚  â”‚ CELERY WORKER    â”‚  â”‚ CELERY BEAT      â”‚               â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚ â”‚
â”‚  â”‚  â”‚ Concurrency: 2   â”‚  â”‚ Scheduler        â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ Memory: 1GB-4GB  â”‚  â”‚ Lazy imports     â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ CPU: 1.0-3.0     â”‚  â”‚ Restart: max 3   â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ Tasks:           â”‚  â”‚ Scheduled tasks: â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ - scrape_job     â”‚  â”‚ - cleanup_old_jobsâ”‚               â”‚ â”‚
â”‚  â”‚  â”‚ - export_excel   â”‚  â”‚ - retry_failed   â”‚               â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DATA LAYER                                                 â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚ â”‚
â”‚  â”‚  â”‚ POSTGRES 15      â”‚  â”‚ REDIS 7          â”‚               â”‚ â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚ â”‚
â”‚  â”‚  â”‚ Port: 5432       â”‚  â”‚ Port: 6379       â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ User: scraper_userâ”‚  â”‚ Auth: password   â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ DB: scraper_db   â”‚  â”‚ Use: queue+cache â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ Health: âœ…       â”‚  â”‚ Health: âœ…       â”‚               â”‚ â”‚
â”‚  â”‚  â”‚ Volume: persist  â”‚  â”‚ Volume: persist  â”‚               â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  SUPPORT SERVICES                                           â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  - CERTBOT: Let's Encrypt (yedek, ÅŸu an kullanÄ±lmÄ±yor)    â”‚ â”‚
â”‚  â”‚  - VOLUMES: postgres_data, redis_data, scraper_results    â”‚ â”‚
â”‚  â”‚  - NETWORK: scraper_network (bridge)                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Tespit Edilen Problemler & Ã‡Ã¶zÃ¼mler

### Problem 1: Frontend Container "Unhealthy"

#### Belirtiler
```bash
docker ps
# scraper_prod_frontend ... Up 5 days (unhealthy)
```

#### TanÄ± SÃ¼reci
```bash
# 1. Frontend loglarÄ± normal gÃ¶rÃ¼nÃ¼yor
docker logs scraper_prod_frontend
# â–² Next.js 14.0.4
#    - Local:        http://localhost:3000
#  âœ“ Ready in 87ms

# 2. Nginx'ten frontend'e eriÅŸim BAÅARILI
docker exec scraper_prod_nginx curl http://frontend:3000
# HTTP 200 OK

# 3. Container iÃ§inden localhost eriÅŸimi BAÅARISIZ
docker exec scraper_prod_frontend wget --spider http://localhost:3000
# wget: can't connect to remote host: Connection refused

# SONUÃ‡: Frontend Ã§alÄ±ÅŸÄ±yor ama healthcheck yÃ¶ntemi yanlÄ±ÅŸ!
```

#### KÃ¶k Neden
Next.js **standalone** build modunda (`output: 'standalone'`), `server.js` dosyasÄ± Ã§alÄ±ÅŸÄ±yor ve aÄŸ dinlemesi farklÄ± ÅŸekilde yapÄ±lÄ±yor. `wget` ile localhost test baÅŸarÄ±sÄ±z oluyor ama Docker network Ã¼zerinden frontend:3000 Ã§alÄ±ÅŸÄ±yor.

#### Ã‡Ã¶zÃ¼m (UygulandÄ±)

**Ã–nceki Healthcheck:**
```yaml
healthcheck:
  test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

**Yeni Healthcheck:**
```yaml
healthcheck:
  test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3000', (r) => process.exit(r.statusCode === 200 ? 0 : 1))\""]
  interval: 30s
  timeout: 10s
  retries: 5  # 3 â†’ 5 (daha toleranslÄ±)
  start_period: 60s  # 40s â†’ 60s (build sÃ¼resi iÃ§in)
```

**Neden Bu Ã‡alÄ±ÅŸÄ±yor:**
- Node.js zaten container'da var (alpine image)
- HTTP request Next.js'in kendi modÃ¼lÃ¼nÃ¼ kullanÄ±yor
- Localhost Ã¼zerinden direkt HTTP GET request
- Exit code 0 (success) veya 1 (fail) dÃ¶ndÃ¼rÃ¼yor

#### DoÄŸrulama
```bash
# Deploy sonrasÄ± test:
docker exec scraper_prod_frontend node -e "require('http').get('http://localhost:3000', (r) => process.exit(r.statusCode === 200 ? 0 : 1))"
echo $?
# Expected: 0 (success)

# 60 saniye sonra container durumu:
docker ps | grep frontend
# Expected: (healthy)
```

---

### Problem 2: Resource Limits Yok

#### Belirtiler
- Container'larda memory/CPU limitleri tanÄ±mlÄ± deÄŸil
- Pi5'te 8GB RAM var ama scraping iÅŸlemlerinde spike olabilir
- OOM (Out of Memory) riski

#### KÃ¶k Neden
docker-compose.prod.yml iÃ§inde `deploy.resources` tanÄ±mlÄ± deÄŸildi. Docker varsayÄ±lan olarak host'un tÃ¼m kaynaklarÄ±nÄ± kullanabilir.

#### Ã‡Ã¶zÃ¼m (UygulandÄ±)

**Backend:**
```yaml
deploy:
  resources:
    limits:
      cpus: '2.0'  # Maksimum 2 core
      memory: 2G   # Maksimum 2GB RAM
    reservations:
      cpus: '0.5'  # Minimum garanti 0.5 core
      memory: 512M # Minimum garanti 512MB
```

**Celery Worker:**
```yaml
deploy:
  resources:
    limits:
      cpus: '3.0'  # Scraping iÃ§in daha fazla CPU
      memory: 4G   # Chromium/Selenium iÃ§in fazla RAM
    reservations:
      cpus: '1.0'
      memory: 1G
command: celery -A celery_app.celery worker --loglevel=info --concurrency=2
```

**Concurrency AyarÄ±:**
- VarsayÄ±lan: CPU core sayÄ±sÄ± (4)
- Yeni: 2 (iki paralel scraping iÅŸi)
- AmaÃ§: Memory spike'larÄ± Ã¶nlemek

#### Kaynak Planlama (Pi5 8GB iÃ§in)

| Servis | Rezervasyon | Limit | KullanÄ±m (Normal) |
|--------|-------------|-------|-------------------|
| Backend | 512MB | 2GB | ~800MB |
| Celery Worker | 1GB | 4GB | ~1.5GB (scraping sÄ±rasÄ±nda 3GB) |
| Frontend | - | - | ~200MB |
| Postgres | - | - | ~150MB |
| Redis | - | - | ~50MB |
| Nginx | - | - | ~20MB |
| Cloudflared | - | - | ~30MB |
| **TOPLAM** | **1.5GB** | **6GB** | **~2.7GB (peak: 5GB)** |
| **KALAN** | **6.5GB** | **2GB** | **System + Buffer** |

---

### Problem 3: Cloudflare Tunnel HatalarÄ± (devtestenv.org)

#### Belirtiler
```bash
docker logs scraper_prod_cloudflared --tail 20
# ERR Request failed error="Unable to reach the origin service"
# dest=http://devtestenv.org/...
# dial tcp 127.0.0.1:3001: connect: connection refused
```

#### Analiz
- `scraper.devtestenv.org` â†’ `localhost:80` âœ… Ã‡ALIÅIYOR
- `devtestenv.org` â†’ `localhost:3001` âŒ PORT KAPALI
- `json2excel.devtestenv.org` â†’ `localhost:8091` âŒ PORT KAPALI

#### KÃ¶k Neden
Cloudflare tunnel config'de 3 domain var ama sadece scraper Ã§alÄ±ÅŸÄ±yor. DiÄŸer projeler henÃ¼z deploy edilmemiÅŸ.

#### Ã‡Ã¶zÃ¼m SeÃ§enekleri

**SeÃ§enek A: DiÄŸer projeleri deploy et**
```bash
# devtestenv.org iÃ§in port 3001'de servis kur
# json2excel iÃ§in port 8091'de servis kur
```

**SeÃ§enek B: Config'den kaldÄ±r (Ã–nerilen)**
```yaml
# /home/ekrem/.cloudflared/config.yml
ingress:
  # Sadece aktif projeyi tut
  - hostname: scraper.devtestenv.org
    service: http://localhost:80
  
  # DiÄŸerlerini kaldÄ±r veya comment out:
  # - hostname: devtestenv.org
  #   service: http://localhost:3001
  
  - service: http_status:404
```

**SeÃ§enek C: Catch-all ile 404 dÃ¶n (Mevcut Durum)**
Åu anki config zaten son kural olarak `http_status:404` dÃ¶nÃ¼yor, bu kabul edilebilir. Sadece log'da hata gÃ¶rÃ¼nÃ¼yor ama iÅŸlevselliÄŸi etkilemiyor.

---

## ğŸ› ï¸ YapÄ±lan Ä°yileÅŸtirmeler

### 1. Docker Compose OptimizasyonlarÄ±

#### a) Frontend Environment Variables (Eklendi)
```yaml
environment:
  # Ã–nceden sadece build-time ARG vardÄ±
  # Åimdi runtime ENV de eklendi:
  NEXT_PUBLIC_API_URL: ${BACKEND_URL}
  NEXT_PUBLIC_GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
  NODE_ENV: production
  PORT: 3000  # â† YENÄ°
  HOSTNAME: "0.0.0.0"  # â† YENÄ°
```

#### b) Resource Limits (Eklendi)
```yaml
# Backend ve Celery Worker'a resource limits eklendi
# Detaylar "Problem 2" bÃ¶lÃ¼mÃ¼nde
```

#### c) Healthcheck Ä°yileÅŸtirmeleri
```yaml
# Frontend: wget â†’ Node.js HTTP
# Retries: 3 â†’ 5
# Start period: 40s â†’ 60s
```

### 2. Maintenance Scripts (Yeni)

#### a) Disk Cleanup Script
```bash
# /opt/scraper/deployment/scripts/cleanup_docker.sh
- Stopped containers temizleme
- Dangling images silme
- Unused volumes (opsiyonel)
- Build cache temizleme
- Ã–nce/sonra disk raporu
```

#### b) Health Check Script
```bash
# /opt/scraper/deployment/scripts/health_check.sh
- Sistem bilgileri (uptime, load, hostname)
- CPU sÄ±caklÄ±ÄŸÄ± (renkli Ã§Ä±ktÄ±)
- RAM kullanÄ±mÄ±
- Disk kullanÄ±mÄ± (uyarÄ± eÅŸikleri)
- Docker container durumlarÄ±
- Container health status (renkli)
- Aktif portlar
- Cloudflare tunnel durumu
```

---

## ğŸ“Š Mevcut Sistem Metrikleri (8 KasÄ±m 2025)

### Hardware Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raspberry Pi 5 - Hardware Status                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Uptime:          12 gÃ¼n 3 saat 42 dakika           â”‚
â”‚  Load Average:    0.02, 0.03, 0.05 (1/5/15 min)     â”‚
â”‚  CPU Temp:        56.5Â°C âœ… (Normal)                â”‚
â”‚  CPU Model:       ARM Cortex-A76 (4 cores)          â”‚
â”‚  CPU Usage:       2-5% âœ… (Ä°deal)                   â”‚
â”‚  RAM Total:       7.9GB                              â”‚
â”‚  RAM Used:        1.6GB (20%) âœ…                    â”‚
â”‚  RAM Available:   6.3GB                              â”‚
â”‚  Swap Used:       35MB / 511MB                       â”‚
â”‚  Disk Total:      58GB                               â”‚
â”‚  Disk Used:       31GB (57%) âš ï¸                     â”‚
â”‚  Disk Available:  24GB                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Resource Usage                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  TYPE           TOTAL     ACTIVE    RECLAIMABLE     â”‚
â”‚  Images         44        10        8.02GB (90%)    â”‚
â”‚  Containers     15        12        3.28KB (0%)     â”‚
â”‚  Volumes        9         7         0B (0%)         â”‚
â”‚  Build Cache    183       0         5.37GB (100%)   â”‚
â”‚                                                      â”‚
â”‚  Total Reclaimable: 13.39GB â† CLEANUP Ã–NERÄ°LÄ°YOR!  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Container Status

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Container Name              Status        Health          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  scraper_prod_nginx          Up 5 days     -               â”‚
â”‚  scraper_prod_frontend       Up 5 days     unhealthyâ†’FIX   â”‚
â”‚  scraper_prod_backend        Up 5 days     healthy âœ…      â”‚
â”‚  scraper_prod_worker         Up 5 days     -               â”‚
â”‚  scraper_prod_beat           Up 5 days     -               â”‚
â”‚  scraper_prod_db             Up 5 days     healthy âœ…      â”‚
â”‚  scraper_prod_redis          Up 5 days     healthy âœ…      â”‚
â”‚  scraper_prod_cloudflared    Up 5 days     -               â”‚
â”‚  scraper_prod_certbot        Up 6 days     -               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Network Ports

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Port    Service           Exposed To              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  80      Nginx             0.0.0.0 (Public)        â”‚
â”‚  443     Nginx             0.0.0.0 (Public)        â”‚
â”‚  3000    Frontend          Docker internal only    â”‚
â”‚  8000    Backend           Docker internal only    â”‚
â”‚  5432    PostgreSQL        Docker internal only    â”‚
â”‚  6379    Redis             Docker internal only    â”‚
â”‚  8090    (Available)       -                       â”‚
â”‚  8091    (Available)       -                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Deployment ProsedÃ¼rÃ¼

### 1. DeÄŸiÅŸiklikleri Deploy Etme

```bash
# Windows (yerel makineden)
cd E:\Programming\bionluk\scraper_trend_etsy

# 1. docker-compose.prod.yml'i kopyala
scp deployment/docker-compose.prod.yml ekrem@192.168.1.143:/opt/scraper/docker-compose.prod.yml

# 2. Maintenance scriptleri kopyala
scp deployment/scripts/*.sh ekrem@192.168.1.143:/opt/scraper/deployment/scripts/

# 3. Pi'ye SSH baÄŸlan
ssh ekrem@192.168.1.143

# 4. Scripts'leri executable yap
chmod +x /opt/scraper/deployment/scripts/*.sh

# 5. Disk temizliÄŸi (opsiyonel ama Ã¶nerilen)
cd /opt/scraper
./deployment/scripts/cleanup_docker.sh

# 6. Servisleri rebuild ve restart
docker compose build frontend backend celery_worker
docker compose up -d

# 7. Health check (60 saniye bekle)
sleep 60
./deployment/scripts/health_check.sh

# 8. Frontend health kontrol
docker ps | grep frontend
# Expected: (healthy)
```

### 2. DoÄŸrulama Testleri

```bash
# Test 1: Frontend health
docker inspect scraper_prod_frontend --format='{{.State.Health.Status}}'
# Expected: healthy

# Test 2: Nginx'ten frontend eriÅŸimi
docker exec scraper_prod_nginx curl -s -o /dev/null -w '%{http_code}\n' http://frontend:3000
# Expected: 200

# Test 3: Backend API
docker exec scraper_prod_nginx curl -s http://backend:8000/health | jq
# Expected: {"status":"healthy",...}

# Test 4: External domain access
curl -I https://scraper.devtestenv.org
# Expected: HTTP/2 200

# Test 5: Resource limits
docker stats --no-stream --format "table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}"
# Backend ve Worker'da limit gÃ¶rÃ¼nmeli
```

### 3. Rollback PlanÄ± (Sorun Ã‡Ä±karsa)

```bash
# Ã–nceki versiyona dÃ¶n
cd /opt/scraper
docker compose down
git checkout HEAD~1 docker-compose.prod.yml  # EÄŸer git kullanÄ±yorsan
# VEYA manuel olarak Ã¶nceki config'i geri yÃ¼kle

docker compose up -d
```

---

## ğŸ“š DiÄŸer Projelere Ã–rnek: Yeni Servis Ekleme

### Senaryo: `blog.devtestenv.org` eklemek istiyorsun

#### AdÄ±m 1: Cloudflare Tunnel'a Yeni Route Ekle

```bash
# Pi5'te
ssh ekrem@192.168.1.143

# 1. Config dosyasÄ±nÄ± dÃ¼zenle
nano /home/ekrem/.cloudflared/config.yml
```

```yaml
tunnel: 1dea088d-ef23-48bc-aca6-a1853f6b1507
credentials-file: /home/ekrem/.cloudflared/1dea088d-ef23-48bc-aca6-a1853f6b1507.json

ingress:
  - hostname: devtestenv.org
    service: http://localhost:3001

  - hostname: json2excel.devtestenv.org
    service: http://localhost:8091

  - hostname: scraper.devtestenv.org
    service: http://localhost:80

  # YENÄ° EKLENEN:
  - hostname: blog.devtestenv.org
    service: http://localhost:8092  # â† Yeni port

  - service: http_status:404
```

```bash
# 2. DNS route ekle
cloudflared tunnel route dns scraper-tunnel blog.devtestenv.org

# 3. Cloudflared container'Ä± restart et
docker compose restart cloudflared

# 4. Log kontrol
docker logs scraper_prod_cloudflared --tail 50
```

#### AdÄ±m 2: Nginx Config GÃ¼ncelle

```bash
nano /opt/scraper/nginx/nginx.conf
```

```nginx
# Yeni server block ekle (port 8092'de dinleyecek)
server {
    listen 8092;
    server_name _;

    location / {
        proxy_pass http://blog_frontend:3000;  # â† Docker service adÄ±
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support (Next.js HMR iÃ§in)
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

```bash
# Config test
docker exec scraper_prod_nginx nginx -t

# Nginx restart
docker compose restart nginx
```

#### AdÄ±m 3: Docker Compose'a Yeni Servis Ekle

```yaml
# docker-compose.prod.yml iÃ§ine ekle:

services:
  # ... mevcut servisler ...

  blog_frontend:
    build:
      context: ./blog_project  # â† Blog projenin dizini
      dockerfile: Dockerfile.prod
    container_name: blog_frontend
    environment:
      NODE_ENV: production
      PORT: 3000
      HOSTNAME: "0.0.0.0"
    networks:
      - scraper_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3000', (r) => process.exit(r.statusCode === 200 ? 0 : 1))\""]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
```

```bash
# Deploy
docker compose up -d blog_frontend

# Test
curl -I https://blog.devtestenv.org
```

#### Ã–zet: Yeni Proje Ekleme Checklist

- [ ] Cloudflare tunnel config'e ingress kuralÄ± ekle
- [ ] `cloudflared tunnel route dns` komutuyla DNS ekle
- [ ] Cloudflared container restart
- [ ] Nginx config'e yeni server block ekle (port mapping)
- [ ] Nginx config test + restart
- [ ] docker-compose.prod.yml'e yeni servis ekle
- [ ] `docker compose up -d <servis_adÄ±>`
- [ ] External eriÅŸim test et
- [ ] Health check doÄŸrula

---

## ğŸ” GÃ¼venlik & Best Practices

### 1. Åu Anki GÃ¼venlik Durumu

**âœ… Ä°yi Olanlar:**
- Cloudflare DDoS korumasÄ± aktif
- Nginx rate limiting var (10 req/s API, 30 req/s genel)
- SSL/TLS otomatik (Cloudflare)
- Container'lar non-root user ile Ã§alÄ±ÅŸÄ±yor (nextjs, postgres vb.)
- Internal portlar sadece Docker network'Ã¼nde aÃ§Ä±k
- Environment variables `.env` dosyasÄ±nda (git'te yok)

**âš ï¸ Ä°yileÅŸtirilebilir:**
- [ ] Database ÅŸifreleri rotate edilebilir
- [ ] Backend API'ye authentication middleware eklenebilir
- [ ] Nginx access log'larÄ± filtrelenebilir (PII verileri iÃ§in)
- [ ] Docker secrets kullanÄ±labilir (ÅŸu an .env file)
- [ ] Fail2ban kurulabilir (brute-force iÃ§in)

### 2. Ã–nerilen GÃ¼venlik Ä°yileÅŸtirmeleri

#### a) Docker Secrets (GeliÅŸmiÅŸ)

```yaml
# docker-compose.prod.yml
secrets:
  db_password:
    file: ./secrets/db_password.txt
  redis_password:
    file: ./secrets/redis_password.txt

services:
  backend:
    secrets:
      - db_password
      - redis_password
    environment:
      DATABASE_URL: postgresql://user:@postgres/db?password_file=/run/secrets/db_password
```

#### b) Fail2ban (Pi5'te)

```bash
# Pi5'te kur
sudo apt install fail2ban -y

# Nginx iÃ§in jail oluÅŸtur
sudo nano /etc/fail2ban/jail.d/nginx.conf
```

```ini
[nginx-limit-req]
enabled = true
filter = nginx-limit-req
action = iptables-multiport[name=ReqLimit, port="http,https"]
logpath = /opt/scraper/logs/nginx/error.log
findtime = 600
bantime = 7200
maxretry = 10
```

#### c) Log Rotation

```bash
# Pi5'te
sudo nano /etc/logrotate.d/docker
```

```
/opt/scraper/logs/nginx/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    create 0640 ekrem ekrem
    sharedscripts
    postrotate
        docker exec scraper_prod_nginx nginx -s reload
    endscript
}
```

### 3. Backup Stratejisi

#### Ã–nerilen Backup PlanÄ±

**GÃ¼nlÃ¼k (Automatic):**
```bash
#!/bin/bash
# /opt/scraper/deployment/scripts/backup_daily.sh

DATE=$(date +%Y%m%d)
BACKUP_DIR="/opt/backups"

# PostgreSQL dump
docker exec scraper_prod_db pg_dump -U scraper_user scraper_db > $BACKUP_DIR/db_$DATE.sql

# Redis dump (optional)
docker exec scraper_prod_redis redis-cli SAVE
cp /var/lib/docker/volumes/scraper_redis_data/_data/dump.rdb $BACKUP_DIR/redis_$DATE.rdb

# Eski backuplarÄ± sil (7 gÃ¼nden eski)
find $BACKUP_DIR -name "*.sql" -mtime +7 -delete
find $BACKUP_DIR -name "*.rdb" -mtime +7 -delete
```

**HaftalÄ±k (Manual veya Cron):**
```bash
# TÃ¼m volumes'i tar.gz olarak yedekle
cd /var/lib/docker/volumes
sudo tar -czf /opt/backups/volumes_$(date +%Y%m%d).tar.gz scraper_*
```

**Cron Job Ekle:**
```bash
crontab -e
```

```cron
# GÃ¼nlÃ¼k backup (sabah 3'te)
0 3 * * * /opt/scraper/deployment/scripts/backup_daily.sh

# HaftalÄ±k full backup (Pazar sabah 4'te)
0 4 * * 0 cd /var/lib/docker/volumes && sudo tar -czf /opt/backups/volumes_$(date +%Y%m%d).tar.gz scraper_*

# GÃ¼nlÃ¼k health check log (her saat baÅŸÄ±)
0 * * * * /opt/scraper/deployment/scripts/health_check.sh >> /var/log/pi_health.log 2>&1
```

---

## ğŸ¯ Sonraki AdÄ±mlar (Ã–ncelik SÄ±rasÄ±yla)

### 1. ACIL (BugÃ¼n yapÄ±lmalÄ±)

- [x] âœ… Frontend healthcheck dÃ¼zeltmesi deploy et
- [x] âœ… Resource limits deploy et
- [ ] ğŸ”„ Docker disk temizliÄŸi yap (13GB boÅŸalacak)
- [ ] ğŸ”„ Health check script'i test et

### 2. YÃœKSEK Ã–NCELÄ°K (Bu hafta)

- [ ] Maintenance scripts'leri cron job olarak ekle
- [ ] Backup stratejisi kur (PostgreSQL dump)
- [ ] Log rotation ayarla
- [ ] Cloudflare tunnel config'i temizle (unused domain'leri kaldÄ±r)

### 3. ORTA Ã–NCELÄ°K (Bu ay)

- [ ] Monitoring tool kur (Netdata veya Prometheus)
- [ ] Fail2ban kur ve ayarla
- [ ] Docker secrets'a geÃ§ (.env yerine)
- [ ] API authentication middleware ekle

### 4. DÃœÅÃœK Ã–NCELÄ°K (Gelecek)

- [ ] SD kartÄ± SSD'ye upgrade (disk hÄ±zÄ± iÃ§in)
- [ ] Multi-region backup (cloud storage)
- [ ] Grafana dashboard oluÅŸtur
- [ ] Alerting sistemi (email/slack)

---

## ğŸ“ Sorun Giderme Rehberi (Claude iÃ§in)

### Senaryo 1: Container Unhealthy

**AdÄ±mlar:**
```bash
# 1. Container loglarÄ±nÄ± kontrol et
docker logs <container_name> --tail 100

# 2. Health check komutunu manuel test et
docker exec <container_name> <healthcheck_command>

# 3. Healthcheck geÃ§miÅŸini gÃ¶r
docker inspect <container_name> --format='{{json .State.Health}}' | jq

# 4. Container'Ä± restart et
docker compose restart <container_name>

# 5. Hala unhealthy ise healthcheck'i kaldÄ±r (geÃ§ici)
# docker-compose.yml iÃ§inde healthcheck: kÄ±smÄ±nÄ± comment out
```

### Senaryo 2: 502 Bad Gateway

**AdÄ±mlar:**
```bash
# 1. Backend/Frontend Ã§alÄ±ÅŸÄ±yor mu?
docker ps | grep -E 'backend|frontend'

# 2. Nginx loglarÄ±
docker logs scraper_prod_nginx --tail 50

# 3. Backend health
docker exec scraper_prod_nginx curl http://backend:8000/health

# 4. Frontend health
docker exec scraper_prod_nginx curl http://frontend:3000

# 5. Nginx config test
docker exec scraper_prod_nginx nginx -t

# 6. TÃ¼m stack'i restart
docker compose restart
```

### Senaryo 3: Out of Memory (OOM)

**Belirtiler:**
```bash
# Container restart oluyor
docker ps
# Exit code 137 (OOM killed)
```

**Ã‡Ã¶zÃ¼m:**
```bash
# 1. Resource kullanÄ±mÄ±nÄ± kontrol et
docker stats --no-stream

# 2. Limits'i artÄ±r (gerekirse)
# docker-compose.prod.yml iÃ§inde memory: 4G â†’ 6G

# 3. Celery concurrency azalt
# command: celery ... --concurrency=2 â†’ --concurrency=1

# 4. Sistem RAM kontrol
free -h

# 5. Swap artÄ±r (geÃ§ici)
sudo swapon -s
sudo fallocate -l 2G /swapfile2
sudo chmod 600 /swapfile2
sudo mkswap /swapfile2
sudo swapon /swapfile2
```

### Senaryo 4: Disk Doldu

**AdÄ±mlar:**
```bash
# 1. Disk durumu
df -h

# 2. Docker kullanÄ±mÄ±
docker system df

# 3. Cleanup (interactive)
/opt/scraper/deployment/scripts/cleanup_docker.sh

# 4. Manuel cleanup (agresif)
docker system prune -af --volumes  # DÄ°KKAT: TÃ¼m unused data silinir!

# 5. LoglarÄ± temizle
sudo journalctl --vacuum-time=7d
sudo find /var/log -name "*.log" -type f -mtime +30 -delete
```

### Senaryo 5: Cloudflare Tunnel Ã‡alÄ±ÅŸmÄ±yor

**AdÄ±mlar:**
```bash
# 1. Container Ã§alÄ±ÅŸÄ±yor mu?
docker ps | grep cloudflared

# 2. LoglarÄ± kontrol et
docker logs scraper_prod_cloudflared --tail 100

# 3. Config dosyasÄ± doÄŸru mu?
cat /home/ekrem/.cloudflared/config.yml

# 4. Token geÃ§erli mi?
# Cloudflare Dashboard â†’ Zero Trust â†’ Tunnels â†’ scraper-tunnel

# 5. Container restart
docker compose restart cloudflared

# 6. Manuel tunnel test
docker exec scraper_prod_cloudflared cloudflared tunnel info
```

---

## ğŸ“– Referans Komutlar (HÄ±zlÄ± EriÅŸim)

### Docker Management

```bash
# Container durumu
docker ps -a

# Loglar (follow mode)
docker logs -f <container_name>

# Container iÃ§ine gir
docker exec -it <container_name> sh

# Container restart
docker compose restart <service_name>

# TÃ¼m stack restart
docker compose down && docker compose up -d

# Resource kullanÄ±mÄ± (real-time)
docker stats

# Disk kullanÄ±mÄ±
docker system df -v

# Temizlik
docker system prune -f
```

### System Monitoring

```bash
# CPU & RAM
htop

# Disk
df -h
du -sh /opt/scraper/*

# SÄ±caklÄ±k
awk '{printf "%.1fÂ°C\n",$1/1000}' /sys/class/thermal/thermal_zone0/temp

# Network
sudo netstat -tlnp
sudo ss -tlnp

# Load
uptime
cat /proc/loadavg
```

### Nginx

```bash
# Config test
docker exec scraper_prod_nginx nginx -t

# Reload
docker exec scraper_prod_nginx nginx -s reload

# Access log (last 100)
docker exec scraper_prod_nginx tail -100 /var/log/nginx/access.log

# Error log
docker exec scraper_prod_nginx tail -100 /var/log/nginx/error.log
```

### Database

```bash
# PostgreSQL shell
docker exec -it scraper_prod_db psql -U scraper_user -d scraper_db

# Quick query
docker exec scraper_prod_db psql -U scraper_user -d scraper_db -c "SELECT COUNT(*) FROM jobs;"

# Backup
docker exec scraper_prod_db pg_dump -U scraper_user scraper_db > backup.sql

# Restore
cat backup.sql | docker exec -i scraper_prod_db psql -U scraper_user -d scraper_db
```

### Redis

```bash
# Redis CLI
docker exec -it scraper_prod_redis redis-cli -a $(grep REDIS_PASSWORD /opt/scraper/.env | cut -d= -f2)

# Memory usage
docker exec scraper_prod_redis redis-cli -a <password> INFO memory

# Keys count
docker exec scraper_prod_redis redis-cli -a <password> DBSIZE
```

---

## ğŸ“ Ã–ÄŸrenilen Dersler & Best Practices

### 1. Next.js Standalone Build

**Ders:** Next.js standalone mode'da healthcheck iÃ§in `wget` yerine Node.js HTTP kullan.

**Neden:** Standalone build'de networking farklÄ± Ã§alÄ±ÅŸÄ±yor, localhost binding beklenmedik davranabiliyor.

**Best Practice:**
```yaml
# âŒ YANLIÅ
test: ["CMD", "wget", "--spider", "http://localhost:3000"]

# âœ… DOÄRU
test: ["CMD-SHELL", "node -e \"require('http').get('http://localhost:3000', ...)\""]
```

### 2. Resource Limits (Pi iÃ§in Kritik)

**Ders:** Raspberry Pi gibi sÄ±nÄ±rlÄ± kaynaklÄ± sistemlerde mutlaka resource limits tanÄ±mla.

**Neden:** Scraping/Chromium gibi uygulamalar memory spike yapabilir, OOM kill olabilir.

**Best Practice:**
```yaml
deploy:
  resources:
    limits:
      memory: 4G  # â† Her zaman tanÄ±mla
      cpus: '2.0'
    reservations:
      memory: 1G  # â† Minimum garanti
```

### 3. Cloudflare Tunnel Config

**Ders:** Tunnel config'de sadece aktif servisleri tut, unused hostname'leri kaldÄ±r.

**Neden:** Log'da gereksiz hata mesajlarÄ±, karmaÅŸÄ±klÄ±k artÄ±ÅŸÄ±.

**Best Practice:**
```yaml
ingress:
  # Sadece production servisleri
  - hostname: scraper.devtestenv.org
    service: http://localhost:80
  
  # Development/test servisleri comment out
  # - hostname: test.devtestenv.org
  #   service: http://localhost:8080
  
  - service: http_status:404
```

### 4. Healthcheck Timing

**Ders:** start_period'u build sÃ¼resine gÃ¶re ayarla, retries'Ä± toleranslÄ± tut.

**Neden:** Slow build/baÅŸlatma unhealthy false-positive'lere sebep olur.

**Best Practice:**
```yaml
healthcheck:
  start_period: 60s  # â† Build + baÅŸlatma sÃ¼resi
  retries: 5         # â† ToleranslÄ± (3 yerine 5)
  interval: 30s      # â† SÄ±k kontrol
  timeout: 10s
```

### 5. Disk Management

**Ders:** Docker'da dÃ¼zenli temizlik yapÄ±lmazsa disk hÄ±zla dolar.

**Neden:** Build cache, unused images, dangling volumes.

**Best Practice:**
```bash
# HaftalÄ±k cron job ekle
0 3 * * 0 docker system prune -f

# Veya script ile
./cleanup_docker.sh
```

### 6. Concurrency Tuning

**Ders:** Celery worker concurrency'sini Pi'nin kaynaklarÄ±na gÃ¶re ayarla.

**Neden:** VarsayÄ±lan (CPU core sayÄ±sÄ±) fazla olabilir, memory spike yapar.

**Best Practice:**
```yaml
# Pi5 (4 core) iÃ§in:
command: celery -A app worker --concurrency=2  # â† CPU_COUNT / 2

# Normal server iÃ§in:
command: celery -A app worker --concurrency=4
```

---

## ğŸ“ Son Notlar (Claude iÃ§in)

### Deployment Durumu

**YapÄ±lan:**
- âœ… Frontend healthcheck dÃ¼zeltildi (wget â†’ node HTTP)
- âœ… Resource limits eklendi (backend 2GB, worker 4GB)
- âœ… Celery concurrency optimize edildi (2)
- âœ… Frontend environment variables eklendi (PORT, HOSTNAME)
- âœ… Start period artÄ±rÄ±ldÄ± (40s â†’ 60s)
- âœ… Maintenance scripts oluÅŸturuldu (cleanup, health check)

**Deploy Edilmesi Gereken:**
```bash
# Bu dosyalar Pi5'e kopyalanÄ±p docker compose up -d yapÄ±lmalÄ±:
- deployment/docker-compose.prod.yml (deÄŸiÅŸti)
- deployment/scripts/cleanup_docker.sh (yeni)
- deployment/scripts/health_check.sh (yeni)
```

**Deployment SonrasÄ± Beklenen:**
- Frontend: (healthy) durumuna geÃ§meli
- TÃ¼m container'lar resource limits ile Ã§alÄ±ÅŸmalÄ±
- Memory kullanÄ±mÄ± daha stabil olmalÄ±

### Monitoring Ã–nerileri

**Netdata Kurulumu (Ã–nerilen):**
```bash
# Pi5'te tek komut:
bash <(curl -Ss https://my-netdata.io/kickstart.sh) --disable-telemetry

# EriÅŸim: http://192.168.1.143:19999
# Cloudflare tunnel eklenebilir: monitoring.devtestenv.org
```

**Netdata AvantajlarÄ±:**
- Real-time monitoring (CPU, RAM, Disk, Network)
- Container-level metrics (Docker plugin)
- Alarm sistemi (email, slack)
- Zero config (otomatik discovery)
- Hafif (20-30MB RAM)

### Kritik Dosyalar

**Mutlaka yedeklenme Ã§alÄ±ÅŸmasÄ± gerekenler:**
```
/opt/scraper/.env                          â† Secrets
/opt/scraper/docker-compose.prod.yml       â† Stack config
/home/ekrem/.cloudflared/                  â† Tunnel credentials
/var/lib/docker/volumes/scraper_*          â† Data (postgres, redis)
```

**Backup Komutu:**
```bash
# Pi5'te
tar -czf /tmp/scraper_backup_$(date +%Y%m%d).tar.gz \
  /opt/scraper/.env \
  /opt/scraper/docker-compose.prod.yml \
  /home/ekrem/.cloudflared/config.yml

# PostgreSQL dump
docker exec scraper_prod_db pg_dump -U scraper_user scraper_db > /tmp/db_$(date +%Y%m%d).sql

# Download to local
scp ekrem@192.168.1.143:/tmp/*_$(date +%Y%m%d).* ./backups/
```

---

## âœ… Checklist: Claude'a VerdiÄŸin Zaman

Bu raporu Claude Sonnet 4.5'e verirken ÅŸunlarÄ± da ekle:

- [x] âœ… Bu rapor (CLAUDE_SONNET_REPORT.md)
- [x] âœ… deployment/docker-compose.prod.yml (gÃ¼ncel versiyon)
- [ ] ğŸ”„ deployment/scripts/*.sh (maintenance scripts)
- [ ] ğŸ”„ nginx/nginx.conf (referans iÃ§in)
- [ ] ğŸ”„ frontend/Dockerfile.prod (referans iÃ§in)

**Claude'a SÃ¶ylemen Gerekenler:**
```
"Bu Raspberry Pi 5'te Ã§alÄ±ÅŸan production scraper uygulamamÄ±n detaylÄ± raporu. 
Frontend unhealthy sorunu ve resource limit problemlerini Ã§Ã¶zdÃ¼m. 
Åimdi bu deÄŸiÅŸiklikleri deploy etmem ve monitoring kurgulamam gerekiyor.
Deployment prosedÃ¼rÃ¼nÃ¼ takip edip, sorun Ã§Ä±karsa troubleshooting rehberini kullan."
```

---

**Rapor Sonu**

Bu rapor tÃ¼m sistem durumunu, yapÄ±lan dÃ¼zeltmeleri, deployment prosedÃ¼rÃ¼nÃ¼ ve troubleshooting rehberini iÃ§ermektedir. Claude Sonnet 4.5 bu bilgilerle sistemi tam olarak anlayÄ±p yÃ¶netebilir.

**HazÄ±rlayan:** GitHub Copilot  
**Tarih:** 8 KasÄ±m 2025, 19:45  
**Versiyon:** 1.0.0
