services:
  scraper:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: kibris-emlak-scraper
    volumes:
      # Persist data directories
      - ./property_details.csv:/app/property_details.csv
      - ./pages:/app/pages
      - ./listings:/app/listings
      - ./reports:/app/reports
      - ./temp:/app/temp
    environment:
      # Python environment
      - PYTHONUNBUFFERED=1
      # Add any custom environment variables here
      # - CUSTOM_VAR=value
    restart: unless-stopped
    networks:
      - scraper-network
    # Resource limits (adjust based on your needs)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    # Override default command for different operations
    # Uncomment one of the following or override via docker-compose run
  # command: python -m scraper.main  # Default scraper
  # command: python -m scraper.extract_data  # Run extractor
  # command: python -m scraper.report  # Generate reports
  # command: python -m scraper.orchard_analysis  # Run orchard analysis
  # command: python -m scraper.generate_agent_report  # Generate Word report
  # command: python -m scraper.search basic "guzelyurt arsa"  # Search example
    # command: /bin/bash  # Interactive shell

  # Optional: Add a scheduled job service using cron
  scraper-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: kibris-emlak-scheduler
    volumes:
      - ./property_details.csv:/app/property_details.csv
      - ./pages:/app/pages
      - ./listings:/app/listings
      - ./reports:/app/reports
      - ./temp:/app/temp
      - ./crontab:/etc/cron.d/scraper-cron:ro
    environment:
      - PYTHONUNBUFFERED=1
    command: >
      sh -c "
      apt-get update && 
      apt-get install -y cron && 
      crontab /etc/cron.d/scraper-cron && 
      cron -f
      "
    restart: unless-stopped
    networks:
      - scraper-network
    profiles:
      - scheduler
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

networks:
  scraper-network:
    driver: bridge
